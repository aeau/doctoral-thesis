
\subsubsection{Variants of MAP-Elites}
% \textbf{Add the following papers}: The paper from Gozalez-duque et al. where they used intelligent trial and error algorithm to find levels suitable to agents~\cite{p9Gonzalez-Duque2020-DifficultyTrialError}. The paper from Schrum et al., where they use interactive evolution to evolve GANs (perhaps fits better as an approach to interactive evolution)~\cite{p9Schrum2020-IE_GAN}. The work by Cully and Demiris where they present a framework for QD, but specifically because of the curiosity score they introduced to select cells~\cite{p9Cully2018-QDFramework}. The work by Cully where he takes the work by Fontaine et al.~\cite{p9fontaine2019covariance} that introduces emitters, and create a set of multi-emitters to generate individuals (or evaluate individuals differently) that outperfom all other map-elites.~\cite{p9cully2020-multiemitter}. The work by Justesen et al., where they extended MAP-Elites with \emph{Adaptive Sampling} and \emph{Drifting-Elites}, discussing about domains where fitness functions and behavior evaluations are stochastic i.e., noisy domains~\cite{p9Justesen2019-MAPElitesNoisyDomains}. The work by Steckel and Schrum where they use different amounts of data to train GANs and used MAP-Elites to explore the diversity of generated levels (this paper is quite new, I guess that they are submitting to GECCO)~\cite{p9steckel2021-MAPElitesGANLodeRunner}. Finally, the work by Gaier et al. where they use Variational Autoencoders to model the highest performing individuals in MAP-Elites and is able to create multiple encodings of the solutions, reducing the dimensionality and direct encoding, as well as reaching high-performance faster~\cite{p9Gaier2020-AutomatingRDMAP-Elites}.
MAP-Elites, a quality-diversity (QD) algorithm, seeks to \emph{illuminate} a \emph{behavior space}
%Unlike traditional optimization algorithms that aim at finding a single best solution, QD algorithms try 
by trying to find the best solutions across a feature-dimension grid~\cite{p9Mouret2015}.
% many diverse solutions. The standard version of MAP-Elites creates a grid of $n$ dimensions, where $n$ is the number of different behavioral characteristics (BC). It then tries to find the best solution in each grid cell~\cite{p9Mouret2015}.
Some versions skip the grid in favour of voronoi tesselation to decide which elite individuals to keep in the map~\cite{p9cvt-mape2016}. Other works combine the effective adaptive search of Covariance Matrix Adaptation Evolution Strategies with a map of elites, yielding large improvements for real-valued representations in terms of both objective value and number of elites discovered~\cite{p9fontaine2019covariance}. 
%This work was extended by Cully, introducing Multi-Emitter MAP-Elites (ME-MAP-Elites)~\cite{p9cully2020-multiemitter}.
ME-MAP-Elites~\cite{p9cully2020-multiemitter} creates a set of emitters to focus on different optimization processes that are active at different generations, generating higher performing and diverse individuals.% than tested baselines.
%has addressed the core optimization process of MAP-Elites, which in its original form consists of rank selection and non-adaptive mutation and crossover. In particular, the CMA-ME algorithm 
%MAP-Elites do away with the grid structure, such as CVT-MAP-Elites, which instead uses 

Constrained MAP-Elites~\cite{p9Khalifa2018}
%was introduced by Khalifa et al.~\cite{p9Khalifa2018} in the context of generating bosses for bullet hell games. The key innovation here is to 
combines divergent search with a two-population approach to constraint satisfaction, taken from the FI-2Pop algorithm~\cite{p9Kimbrough2008}. Constrained MAP-Elites has been used as the basis for subsequent experiments, e.g., to find sets of levels implementing diverse game mechanics~\cite{p9charity2020mech}. This algorithm was later combined with interactive evolution to yield the aforementioned Interactive Constrained MAP-Elites~\cite{p9Alvarez2020-ICMAPE}. %\cite{p9alvarez2019empowering} 
Moreover, MAP-Elites has been shown to be robust at adapting to changing conditions after running the algorithm thanks to its generated behavioral repertoire. This was proposed and tested in the intelligent trial-and-error algorithm~\cite{p9Cully2015-qdRobotsAnimals,Gonzalez-Duque2020-DifficultyTrialError}. 
%In games, this algorithm was used by Gonzalez-Duque et al. to evolve a repertoire of levels suited to different agents and finding levels difficult enough for a different set of agents in a few trials~\cite{p9Gonzalez-Duque2020-DifficultyTrialError}.
Related work extended MAP-Elites with \emph{Adaptive Sampling} and \emph{Drifting-Elites} to be more robust in noisy environments and domains where the fitness and behavior evaluation might be stochastic such as games~\cite{p9Justesen2019-MAPElitesNoisyDomains}.

% MAP-Elites can also be used to analyze quality-diverse content 

% MAP-Elites' excellent search for quality-diverse content, and grid-based repertoire have also been used 


% to explore the QD characteristics of other generative approaches such as the work  be also used as was used by Steckel and Schrum to explore the QD characteristics of multiple \textit{Generative Adversarial Networks}

% The work by Steckel and Schrum where they use different amounts of data to train GANs and used MAP-Elites to explore the diversity of generated levels (this paper is quite new, I guess that they are submitting to GECCO)~\cite{p9steckel2021-MAPElitesGANLodeRunner}. 


% and have highlighted the benefits from its generated repertoire for more than creating diverse individuals, but also to allow rapid adaptation~\cite{p9Cully2015-qdRobotsAnimals,Gonzalez-Duque2020-DifficultyTrialError}. The paper from Gozalez-duque et al. where they used intelligent trial and error algorithm to find levels suitable to agents~\cite{p9Gonzalez-Duque2020-DifficultyTrialError}.



%---

% Alternatively, it could be a subsection on interactive evolution and QD algorithm. I think we should introduce the reader to the Interactive Constrained MAP-Elites~\cite{p9alvarez2019empowering} and the evaluation done in the Journal paper~\cite{p9Alvarez2020-ICMAPE}, that's probably the best thing for this section. and perhaps describe other approaches, how MAP-Elites has being used and evaluated; Baba is Y'all~\cite{p9charity2020baba}, mech-elites~\cite{p9charity2020mech}, Talakat~\cite{p9Khalifa2018}, intentional level design~\cite{p9Khalifa2019-intentionalCompLevel}.. Finally, we need to define what is adaptability and stability!  (so is clear what we mean with that throughout the paper)and perhaps concepts like fertility~\cite{p9Ashlock2018-fertility} and evolvability~\cite{p9doncieux2020-noveltyEvolvability}? 

% We should briefly introduce the IC-MAP-Elites and the possible dimensions so is not alien for the reader what it is, as well as briefly writing about our finding in the TOG paper where we analyzed the expressive range in an static environment (no changes over time in the design).


% \begin{itemize}
%     \item Describe other approaches, how MAP-Elites have been used and evaluated. IC MAP-Elites but also other approaches.
%     \item perhaps it can be interesting to present other QD approaches that have benefit from interactive evolution? classic examples such as with novelty search, also the GECCO paper from Schrum et al.~\cite{p9schrum2020-interactiveEAGAN}, Perhaps this should go to the background.
%     \item Might be interesting in the conclusions to bring back the idea of improving the MAP-Elites selection step.
% \end{itemize}

% Usually MAP-Elites have been used in static environments [even if it is in interactive tools], where MAP-Elites can generate diverse and high-performing individuals to a greater extent than previously QD algorithms and classic EAs~\cite{p9Mouret2015}. To our knowledge, the only interactive use of MAP-Elites where a human can interact with the algorithm by different means, and conducts a continuous evolution adapting to changes is Applied to dungeons - EDD~\cite{p9alvarez2019empowering}.  

% Also the inherent relationship presented among cells of elites, particularly, when mapped and presented to the user as it is done in EDD, was used by Alvarez and Font as the main part to model a preference model of the user, given the selection of an elite by the user~\cite{p9Alvarez2020-DesignerPreference}. 

% If we revamp this paper to discuss more level design and level design features, I think this could be a good chapter where we introduce more about MAP-Elites and level design generation. 

% In this paper we explore, analyze and discuss the dynamics of QD algorithms, using specifically, the Interactive Constrained MAP-Elites in the domain of level generation of 2d adventure games. Through this we explore how IC MAP-Elites responds, reacts, and adapts to the editions and changes done by a designer in a mixed-initiative loop--- the stability of the algorithm to constantly explore high-performing solutions in the search space, and the benefits that come with the interactive loop between designer and algorithm, for the algorithm to explore previously seemed mutually exclusive regions of the search space. 